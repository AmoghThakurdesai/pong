# -*- coding: utf-8 -*-
"""linreg-multiple-variables.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X4TtcK_CH2j365Y3bQUDXrRrlC88azNl

# Linear Reg with Multiple Variables
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

FILE_PATH = "/media/amogh193/Data/PythonFiles/assignment/fullstackapp/seaborn-data-master/dataset_names.txt"
SEABORN_FILE_PATH = "/media/amogh193/Data/PythonFiles/assignment/fullstackapp/seaborn-data-master"
import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All"
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

df = pd.read_csv("https://raw.githubusercontent.com/mwaskom/seaborn-data/master/mpg.csv",sep=",")
df["origin"] = pd.Categorical(df["origin"])
df["origin"] = df.origin.cat.codes

df.drop("name",axis=1,inplace = True)

df = df.astype(float)
df = df.fillna(0)
m = df.shape[0]
Y = df["mpg"].to_numpy().reshape((m,1))
X = df.drop("mpg",axis=1)

colmeans = {}
colstds = {}
for col in X.columns:
    colmeans[col] = X[col].mean().astype(float)
    colstds[col] = X[col].std().astype(float)
    X[col] = (X[col] - colmeans[col])/colstds[col]
X = np.hstack((np.ones((m,1)),X.to_numpy()))
theta = np.random.random((X.shape[1],1))
X,Y.shape,theta.shape

def model(t,x):
    return x.dot(t)
def error(t,x,y):
    return model(t,x) - y
def cost(t,x,y):
    constant = 1/(2*m)
    return constant * np.sum(error(t,x,y)**2)
costhistory = []
def grad_descent(t,x,y,epochs,alpha):
    for i in range(0,epochs):
        temp = np.zeros(t.shape)
        dj_dt =  np.zeros(t.shape)
        for j in range(0,t.shape[0]):
            dj_dt[j] = (1/m)*np.sum(np.multiply(error(t,x,y), x[:,j].reshape(m,1)))
            temp[j] = t[j] - (alpha*(dj_dt[j]))

        for k in range(0,t.shape[0]):
            t[k] = temp[k]
        costhistory.append(cost(t,x,y))

    return t

finaltheta = grad_descent(theta,X,Y,1000,1e-1)
# import matplotlib.pyplot as plt
# plt.scatter(x = np.arange(X.shape[0]), y = Y)
# plt.plot(model(finaltheta, X))
# plt.show()


def linreg(x):
    x = np.array(x)
    count = 0
    for i,j in zip([1.,]+(list(colmeans.values())),[0.]+(list(colstds.values()))):
        x[count] = (x[count]-i)/j
        count+=1;
    x[0]=1.0
    result = model(finaltheta,x)
    print(result[0])
    return result

def selecttable(selected):
    seldata = 0 # index of selected data in dataset table
    f = open(FILE_PATH,'r')
    datasetnames = f.read().split()
    tableheading = datasetnames[selected]
    f.close()
    df = pd.read_csv(f"{SEABORN_FILE_PATH}/csv/{datasetnames[selected]}.csv")
    table = df.to_html()
    return table,tableheading,datasetnames
    